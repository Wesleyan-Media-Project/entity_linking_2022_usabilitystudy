{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "55ZCFMuu0TYg"
      },
      "source": [
        "# Environment Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hmPosWh3IlLG"
      },
      "source": [
        "### **This section must be run before attempting to execute any other sections' code cells in order to ensure that all proper packages are installed.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "291NP1oQcied",
        "outputId": "a93515a7-81b0-4ccb-871d-aa9046b47679",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python version is already 3.10 (3.10.12 (main, Nov  6 2024, 20:22:13) [GCC 11.4.0]).\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "import os\n",
        "\n",
        "# Check Python version\n",
        "current_version = sys.version_info\n",
        "\n",
        "if current_version.major != 3 or current_version.minor != 10:\n",
        "    print(f\"Current Python version is {current_version.major}.{current_version.minor}.\")\n",
        "    print(\"Switching to Python 3.10. Please wait...\")\n",
        "\n",
        "    # Install Python 3.10\n",
        "    !sudo apt-get update\n",
        "    !sudo apt-get install python3.10 python3.10-distutils -y\n",
        "\n",
        "    # Install virtualenv if not installed\n",
        "    !pip install virtualenv\n",
        "\n",
        "    # Create a virtual environment using Python 3.10\n",
        "    !virtualenv -p python3.10 py310_env\n",
        "    !source py310_env/bin/activate\n",
        "\n",
        "    print(\"Python 3.10 environment is ready. Restart the notebook and activate the virtual environment to use it.\")\n",
        "else:\n",
        "    print(f\"Python version is already 3.10 ({sys.version}).\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "collapsed": true,
        "id": "rWuFfV-ZdGK0",
        "outputId": "8bd3d01f-5b2f-4484-92d0-89f27e324644",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting spacy==3.2.4\n",
            "  Downloading spacy-3.2.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (23 kB)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.8 in /usr/local/lib/python3.10/dist-packages (from spacy==3.2.4) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy==3.2.4) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy==3.2.4) (1.0.11)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy==3.2.4) (2.0.10)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy==3.2.4) (3.0.9)\n",
            "Collecting thinc<8.1.0,>=8.0.12 (from spacy==3.2.4)\n",
            "  Downloading thinc-8.0.17-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (14 kB)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from spacy==3.2.4) (0.7.11)\n",
            "Collecting wasabi<1.1.0,>=0.8.1 (from spacy==3.2.4)\n",
            "  Downloading wasabi-0.10.1-py3-none-any.whl.metadata (28 kB)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from spacy==3.2.4) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy==3.2.4) (2.0.10)\n",
            "Collecting typer<0.5.0,>=0.3.0 (from spacy==3.2.4)\n",
            "  Downloading typer-0.4.2-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting click<8.1.0 (from spacy==3.2.4)\n",
            "  Downloading click-8.0.4-py3-none-any.whl.metadata (3.2 kB)\n",
            "Collecting pathy>=0.3.5 (from spacy==3.2.4)\n",
            "  Downloading pathy-0.11.0-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy==3.2.4) (4.66.6)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from spacy==3.2.4) (1.26.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy==3.2.4) (2.32.3)\n",
            "Collecting pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 (from spacy==3.2.4)\n",
            "  Downloading pydantic-1.8.2-py3-none-any.whl.metadata (103 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.1/103.1 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy==3.2.4) (3.1.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy==3.2.4) (75.1.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy==3.2.4) (24.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy==3.2.4) (3.5.0)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy==3.2.4) (1.3.0)\n",
            "Collecting smart-open<7.0.0,>=5.2.1 (from pathy>=0.3.5->spacy==3.2.4)\n",
            "  Downloading smart_open-6.4.0-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting pathlib-abc==0.1.1 (from pathy>=0.3.5->spacy==3.2.4)\n",
            "  Downloading pathlib_abc-0.1.1-py3-none-any.whl.metadata (18 kB)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4->spacy==3.2.4) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy==3.2.4) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy==3.2.4) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy==3.2.4) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy==3.2.4) (2024.8.30)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy==3.2.4) (3.0.2)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy==3.2.4) (1.2.1)\n",
            "Downloading spacy-3.2.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.1/6.1 MB\u001b[0m \u001b[31m27.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading click-8.0.4-py3-none-any.whl (97 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.5/97.5 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pathy-0.11.0-py3-none-any.whl (47 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.3/47.3 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pathlib_abc-0.1.1-py3-none-any.whl (23 kB)\n",
            "Downloading pydantic-1.8.2-py3-none-any.whl (126 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.0/126.0 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading thinc-8.0.17-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (659 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m659.5/659.5 kB\u001b[0m \u001b[31m37.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typer-0.4.2-py3-none-any.whl (27 kB)\n",
            "Downloading wasabi-0.10.1-py3-none-any.whl (26 kB)\n",
            "Downloading smart_open-6.4.0-py3-none-any.whl (57 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.0/57.0 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: wasabi, smart-open, pydantic, pathlib-abc, click, typer, thinc, pathy, spacy\n",
            "  Attempting uninstall: wasabi\n",
            "    Found existing installation: wasabi 1.1.3\n",
            "    Uninstalling wasabi-1.1.3:\n",
            "      Successfully uninstalled wasabi-1.1.3\n",
            "  Attempting uninstall: smart-open\n",
            "    Found existing installation: smart-open 7.0.5\n",
            "    Uninstalling smart-open-7.0.5:\n",
            "      Successfully uninstalled smart-open-7.0.5\n",
            "  Attempting uninstall: pydantic\n",
            "    Found existing installation: pydantic 2.10.2\n",
            "    Uninstalling pydantic-2.10.2:\n",
            "      Successfully uninstalled pydantic-2.10.2\n",
            "  Attempting uninstall: click\n",
            "    Found existing installation: click 8.1.7\n",
            "    Uninstalling click-8.1.7:\n",
            "      Successfully uninstalled click-8.1.7\n",
            "  Attempting uninstall: typer\n",
            "    Found existing installation: typer 0.14.0\n",
            "    Uninstalling typer-0.14.0:\n",
            "      Successfully uninstalled typer-0.14.0\n",
            "  Attempting uninstall: thinc\n",
            "    Found existing installation: thinc 8.2.5\n",
            "    Uninstalling thinc-8.2.5:\n",
            "      Successfully uninstalled thinc-8.2.5\n",
            "  Attempting uninstall: spacy\n",
            "    Found existing installation: spacy 3.7.5\n",
            "    Uninstalling spacy-3.7.5:\n",
            "      Successfully uninstalled spacy-3.7.5\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "albumentations 1.4.20 requires pydantic>=2.7.0, but you have pydantic 1.8.2 which is incompatible.\n",
            "dask 2024.10.0 requires click>=8.1, but you have click 8.0.4 which is incompatible.\n",
            "en-core-web-sm 3.7.1 requires spacy<3.8.0,>=3.7.2, but you have spacy 3.2.4 which is incompatible.\n",
            "flask 3.0.3 requires click>=8.1.3, but you have click 8.0.4 which is incompatible.\n",
            "langchain 0.3.9 requires pydantic<3.0.0,>=2.7.4, but you have pydantic 1.8.2 which is incompatible.\n",
            "langchain-core 0.3.21 requires pydantic<3.0.0,>=2.5.2; python_full_version < \"3.12.4\", but you have pydantic 1.8.2 which is incompatible.\n",
            "openai 1.54.5 requires pydantic<3,>=1.9.0, but you have pydantic 1.8.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed click-8.0.4 pathlib-abc-0.1.1 pathy-0.11.0 pydantic-1.8.2 smart-open-6.4.0 spacy-3.2.4 thinc-8.0.17 typer-0.4.2 wasabi-0.10.1\n",
            "Requirement already satisfied: numpy==1.26.4 in /usr/local/lib/python3.10/dist-packages (1.26.4)\n",
            "Collecting pandas==2.1.1\n",
            "  Downloading pandas-2.1.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
            "Requirement already satisfied: numpy>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas==2.1.1) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas==2.1.1) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas==2.1.1) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas==2.1.1) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas==2.1.1) (1.16.0)\n",
            "Downloading pandas-2.1.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.3/12.3 MB\u001b[0m \u001b[31m81.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pandas\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 2.2.2\n",
            "    Uninstalling pandas-2.2.2:\n",
            "      Successfully uninstalled pandas-2.2.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.1.1 which is incompatible.\n",
            "mizani 0.13.0 requires pandas>=2.2.0, but you have pandas 2.1.1 which is incompatible.\n",
            "plotnine 0.14.3 requires pandas>=2.2.0, but you have pandas 2.1.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed pandas-2.1.1\n"
          ]
        }
      ],
      "source": [
        "!pip3 install spacy==3.2.4\n",
        "!pip3 install numpy==1.26.4\n",
        "!pip3 install pandas==2.1.1\n",
        "\n",
        "# To check versions uncomment:\n",
        "#!pip3 list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "B5yJelC6bdaP",
        "outputId": "1d49a7ed-7bcf-4214-a2b6-346f7ea1fe6b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: rpy2 in /usr/local/lib/python3.10/dist-packages (3.4.2)\n",
            "Requirement already satisfied: cffi>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from rpy2) (1.17.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from rpy2) (3.1.4)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.10/dist-packages (from rpy2) (2024.2)\n",
            "Requirement already satisfied: tzlocal in /usr/local/lib/python3.10/dist-packages (from rpy2) (5.2)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.10.0->rpy2) (2.22)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->rpy2) (3.0.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install rpy2\n",
        "%load_ext rpy2.ipython"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "collapsed": true,
        "id": "rDqsLG-jd1TN",
        "outputId": "835d7f84-84a2-47a9-852f-4da31e775db8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: Installing package into ‘/usr/local/lib/R/site-library’\n",
            "(as ‘lib’ is unspecified)\n",
            "\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: trying URL 'https://cran.rstudio.com/src/contrib/dplyr_1.1.4.tar.gz'\n",
            "\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: Content type 'application/x-gzip'\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]:  length 1207521 bytes (1.2 MB)\n",
            "\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: \n",
            "\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: downloaded 1.2 MB\n",
            "\n",
            "\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: \n",
            "\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: \n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: The downloaded source packages are in\n",
            "\t‘/tmp/RtmpSBy6Ou/downloaded_packages’\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: \n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: \n",
            "\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: Installing package into ‘/usr/local/lib/R/site-library’\n",
            "(as ‘lib’ is unspecified)\n",
            "\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: trying URL 'https://cran.rstudio.com/src/contrib/data.table_1.16.2.tar.gz'\n",
            "\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: Content type 'application/x-gzip'\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]:  length 5490076 bytes (5.2 MB)\n",
            "\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: \n",
            "\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: downloaded 5.2 MB\n",
            "\n",
            "\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: \n",
            "\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: \n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: The downloaded source packages are in\n",
            "\t‘/tmp/RtmpSBy6Ou/downloaded_packages’\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: \n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: \n",
            "\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: Installing package into ‘/usr/local/lib/R/site-library’\n",
            "(as ‘lib’ is unspecified)\n",
            "\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: trying URL 'https://cran.rstudio.com/src/contrib/stringr_1.5.1.tar.gz'\n",
            "\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: Content type 'application/x-gzip'\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]:  length 176599 bytes (172 KB)\n",
            "\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: \n",
            "\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: downloaded 172 KB\n",
            "\n",
            "\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: \n",
            "\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: \n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: The downloaded source packages are in\n",
            "\t‘/tmp/RtmpSBy6Ou/downloaded_packages’\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: \n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: \n",
            "\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: Installing package into ‘/usr/local/lib/R/site-library’\n",
            "(as ‘lib’ is unspecified)\n",
            "\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: trying URL 'https://cran.rstudio.com/src/contrib/tidyr_1.3.1.tar.gz'\n",
            "\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: Content type 'application/x-gzip'\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]:  length 809058 bytes (790 KB)\n",
            "\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: \n",
            "\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: downloaded 790 KB\n",
            "\n",
            "\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: \n",
            "\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: \n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: The downloaded source packages are in\n",
            "\t‘/tmp/RtmpSBy6Ou/downloaded_packages’\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: \n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: \n",
            "\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: Installing package into ‘/usr/local/lib/R/site-library’\n",
            "(as ‘lib’ is unspecified)\n",
            "\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: also installing the dependencies ‘R.oo’, ‘R.methodsS3’\n",
            "\n",
            "\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: trying URL 'https://cran.rstudio.com/src/contrib/R.oo_1.27.0.tar.gz'\n",
            "\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: Content type 'application/x-gzip'\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]:  length 384222 bytes (375 KB)\n",
            "\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: \n",
            "\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: downloaded 375 KB\n",
            "\n",
            "\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: trying URL 'https://cran.rstudio.com/src/contrib/R.methodsS3_1.8.2.tar.gz'\n",
            "\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: Content type 'application/x-gzip'\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]:  length 24131 bytes (23 KB)\n",
            "\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: \n",
            "\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: downloaded 23 KB\n",
            "\n",
            "\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: trying URL 'https://cran.rstudio.com/src/contrib/R.utils_2.12.3.tar.gz'\n",
            "\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: Content type 'application/x-gzip'\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]:  length 364188 bytes (355 KB)\n",
            "\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: \n",
            "\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: downloaded 355 KB\n",
            "\n",
            "\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: \n",
            "\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: \n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: The downloaded source packages are in\n",
            "\t‘/tmp/RtmpSBy6Ou/downloaded_packages’\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: \n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: \n",
            "\n"
          ]
        }
      ],
      "source": [
        "%%R\n",
        "install.packages(\"dplyr\")\n",
        "install.packages(\"data.table\")\n",
        "install.packages(\"stringr\")\n",
        "install.packages(\"tidyr\")\n",
        "install.packages(\"R.utils\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mounts Google Drive so you can import external dependencies (e.g., trained_entity_linker.zip)\n",
        "\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "pu0Xi6TlkSPx",
        "outputId": "73baa229-f7af-4664-b03f-420c9d5a5591",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E8KUgcZeNK3-"
      },
      "source": [
        "### Note: If you plan on using the **pre-trained entity linker model** for use with this code (```trained_entity_linker.zip```), you can now move directly to the inference section of the notebook!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uw1nuufm0ZrV"
      },
      "source": [
        "# knowledge_base"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_l_qtnpnB3hB"
      },
      "source": [
        "Steps to take before attempting to run knowledge_base:\n",
        "\n",
        "- **Make sure that ```person_2022.csv```, ```wmpcand_120223_wmpid``` and ```bp2022_house_scraped_face_jasmine.xlsx``` are uploaded onto Google Drive. If they are not directly located in your main drive (e.g, they are in a folder) then the paths used in the code cells must be updated.**\n",
        "\n",
        "  - Files [```person_2022.csv```](https://github.com/Wesleyan-Media-Project/datasets/blob/main/people/person_2022.csv), [```wmpcand_120223_wmpid```](https://github.com/Wesleyan-Media-Project/datasets/blob/main/candidates/wmpcand_120223_wmpid.csv) and [```bp2022_house_scraped_face_jasmine.xlsx```](https://github.com/Wesleyan-Media-Project/face_url_scraper_2022/blob/main/data/bp2022_house_scraped_face_jasmine.xlsx) can be downloaded/uploaded using the links provided.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8ikPrFHG0rlK"
      },
      "outputs": [],
      "source": [
        "%%R\n",
        "library(dplyr)\n",
        "library(haven)\n",
        "library(data.table)\n",
        "library(stringr)\n",
        "library(quanteda)\n",
        "library(readxl)\n",
        "library(tidyr)\n",
        "\n",
        "setwd(\"./\")\n",
        "\n",
        "# File paths\n",
        "# In\n",
        "\n",
        "# These files are located in our datasets repository (https://github.com/Wesleyan-Media-Project/datasets)\n",
        "# Make sure that these files are uploaded into the colab environment before attempting to run\n",
        "\n",
        "path_people_file <- \"/content/drive/MyDrive/person_2022.csv\"\n",
        "path_cand_file <- \"/content/drive/MyDrive/wmpcand_120223_wmpid.csv\"\n",
        "# Out\n",
        "path_kb <- \"entity_kb.csv\"\n",
        "\n",
        "\n",
        "# People file\n",
        "people <- fread(path_people_file, encoding = \"UTF-8\", data.table = F)\n",
        "# Create some additional person categories\n",
        "people$pubhealth <- ifelse(people$face_category == \"public health related\", 1, 0)\n",
        "people$cabinet <- ifelse(people$face_category == \"cabinet\", 1, 0)\n",
        "people$historical <- ifelse(people$face_category == \"historical figures\", 1, 0)\n",
        "# In case any of these variables contain NAs (they largely don't any more)\n",
        "# Make them 0s instead\n",
        "people$supcourt_2022[is.na(people$supcourt_2022)] <- 0\n",
        "people$supcourt_former[is.na(people$supcourt_former)] <- 0\n",
        "people$currsen_2022[is.na(people$currsen_2022)] <- 0\n",
        "people$prompol[is.na(people$prompol)] <- 0\n",
        "people$former_uspres[is.na(people$former_uspres)] <- 0\n",
        "people$intl_leaders[is.na(people$intl_leaders)] <- 0\n",
        "people$gov2022_gencd[is.na(people$gov2022_gencd)] <- 0\n",
        "\n",
        "# Make sure there are no duplicate people\n",
        "if (any(duplicated(people$wmpid))) {\n",
        "  stop(\"There are duplicate people.\")\n",
        "}\n",
        "\n",
        "\n",
        "# Candidate file\n",
        "# Make sure that genelect is 1 so we ignore duplicate versions of the same candidate who ran for different offices but only made it to the general election in one\n",
        "# Also retain only relevant variables\n",
        "cands <- fread(path_cand_file, encoding = \"UTF-8\", data.table = F)\n",
        "cands <- cands %>%\n",
        "  filter(genelect_cd == 1) %>%\n",
        "  select(wmpid, genelect_cd, cand_id, cand_office, cand_office_st, cand_office_dist, cand_party_affiliation)\n",
        "# Make sure there are no duplicate candidates\n",
        "if (any(duplicated(cands$wmpid))) {\n",
        "  stop(\"There are duplicate candidates.\")\n",
        "}\n",
        "\n",
        "# Merge candidate file into people file\n",
        "people <- left_join(people, cands, by = \"wmpid\")\n",
        "\n",
        "# Restrict to only 2022 candidates and other relevant people\n",
        "# Also retain only relevant variables\n",
        "people <- people %>%\n",
        "  filter(genelect_cd == 1 | supcourt_2022 == 1 | supcourt_former == 1 | currsen_2022 == 1 | prompol == 1 | former_uspres == 1 | intl_leaders == 1 | gov2022_gencd == 1 | pubhealth == 1 | cabinet == 1 | historical == 1) %>%\n",
        "  select(wmpid, full_name, first_name, last_name, fecid_2022a, fecid_2022b, genelect_cd, supcourt_2022, supcourt_former, currsen_2022, prompol, former_uspres, intl_leaders, gov2022_gencd, pubhealth, cabinet, historical, cand_id, cand_office, cand_office_st, cand_office_dist, cand_party_affiliation)\n",
        "\n",
        "\n",
        "entities_candidate <- people$full_name\n",
        "\n",
        "tks <- tokens(entities_candidate)\n",
        "#---- FIRST NAME\n",
        "# the first word is always the first name\n",
        "people$first_name_extracted <- unlist(lapply(tks, function(x) {\n",
        "  x[1]\n",
        "}))\n",
        "\n",
        "#---- LAST NAME\n",
        "# If the name consists of two words, then the second one is the last name\n",
        "people$last_name_extracted <- unlist(lapply(tks, function(x) {\n",
        "  if (length(x) == 2) {\n",
        "    x[2]\n",
        "  } else {\n",
        "    NA\n",
        "  }\n",
        "}))\n",
        "# If the name consists of more than two words, then the last one is the last name\n",
        "last_name_temp <- unlist(lapply(tks, function(x) {\n",
        "  if (length(x) > 2) {\n",
        "    x[length(x)]\n",
        "  } else {\n",
        "    NA\n",
        "  }\n",
        "}))\n",
        "people$last_name_extracted[is.na(last_name_temp) == F] <- last_name_temp[is.na(last_name_temp) == F]\n",
        "# if the last word is jr or sr, the second-to last word is the last name\n",
        "last_word_temp <- unlist(lapply(tks, function(x) {\n",
        "  x[length(x)]\n",
        "}))\n",
        "jr_temp_indices <- which(last_word_temp %in% c(\".\", \"Jr\", \"Sr\"))\n",
        "jr_temp_names <- entities_candidate[jr_temp_indices]\n",
        "jr_temp_suffix <- str_extract(jr_temp_names, \"[J|S]r\")\n",
        "people$suffix_name_extracted <- NA\n",
        "people$suffix_name_extracted[jr_temp_indices] <- jr_temp_suffix\n",
        "jr_temp_names_without_suffix <- str_remove(jr_temp_names, \" [J|S]r.?\") # remove Jr/Sr + 0 or more occurence of .\n",
        "jr_temp_names_without_suffix_tks <- tokens(jr_temp_names_without_suffix)\n",
        "jr_temp_last_names <- unlist(lapply(jr_temp_names_without_suffix_tks, function(x) {\n",
        "  x[length(x)]\n",
        "}))\n",
        "people$last_name_extracted[jr_temp_indices] <- jr_temp_last_names\n",
        "\n",
        "\n",
        "# the II, the III\n",
        "II_temp_indices <- which(last_word_temp %in% c(\"II\", \"III\"))\n",
        "II_temp_names <- entities_candidate[II_temp_indices]\n",
        "II_temp_suffix <- str_extract(II_temp_names, \"II+\")\n",
        "people$suffix_name_extracted[II_temp_indices] <- II_temp_suffix\n",
        "II_temp_names_without_suffix <- str_remove(II_temp_names, \" II+\") # remove II/III\n",
        "II_temp_names_without_suffix_tks <- tokens(II_temp_names_without_suffix)\n",
        "II_temp_last_names <- unlist(lapply(II_temp_names_without_suffix_tks, function(x) {\n",
        "  x[length(x)]\n",
        "}))\n",
        "people$last_name_extracted[II_temp_indices] <- II_temp_last_names\n",
        "\n",
        "#---- MIDDLE NAMES\n",
        "name_len <- unlist(lapply(tks, length))\n",
        "no_middle_name <- which(name_len == 2)\n",
        "no_middle_name <- sort(unique(c(no_middle_name, jr_temp_indices, II_temp_indices)))\n",
        "middle_name_indices <- (1:nrow(people))[which((1:nrow(people) %in% no_middle_name) == F)] # people who do have middle names\n",
        "tks_middle_names <- tks[middle_name_indices]\n",
        "tks_middle_names <- lapply(tks_middle_names, function(x) {\n",
        "  x[-1]\n",
        "}) # remove the first word\n",
        "tks_middle_names <- lapply(tks_middle_names, function(x) {\n",
        "  x[-length(x)]\n",
        "}) # remove the last word\n",
        "tks_middle_names <- lapply(tks_middle_names, paste0, collapse = \" \") # combine them and make a space so that multiple middle names, or \"De La\" etc. get resolved\n",
        "tks_middle_names <- str_replace_all(tks_middle_names, \" \\\\.\", \"\\\\.\") # this does create a problem with periods, clean them up\n",
        "tks_middle_names <- str_replace(tks_middle_names, \"^\\\\.\", \"\") # remove periods if they are the first char\n",
        "tks_middle_names <- str_trim(tks_middle_names) # clean up spaces at beginning/end\n",
        "people$middle_name_extracted <- NA\n",
        "people$middle_name_extracted[middle_name_indices] <- tks_middle_names\n",
        "people$middle_name_extracted[which(people$middle_name_extracted == \"\")] <- NA # some people ended up with an empty middle name, remove\n",
        "\n",
        "\n",
        "# ----\n",
        "# JASMINE'S FIXES to candidate names\n",
        "# This file is located in our face_url_scraper_2022 repository (https://github.com/Wesleyan-Media-Project/face_url_scraper_2022)\n",
        "# Make sure the face_url_scraper_2022 folder is located in the same directory as entity_linking_2022\n",
        "fixes <- read_xlsx(\"/content/bp2022_house_scraped_face_jasmine.xlsx\") # nolint: line_length_linter.\n",
        "fixes <- fixes %>%\n",
        "  select(wmpid, cand_name, full_name, starts_with(\"hc\")) %>%\n",
        "  select(-c(hc_face_note, hc_face_url, hc_office_district, hc_office_district_note))\n",
        "\n",
        "people <- left_join(people, fixes, by = \"wmpid\")\n",
        "\n",
        "# Overwrite with Jasmine's fixes\n",
        "people$first_name_extracted[is.na(people$hc_first_name) == F] <- people$hc_first_name[is.na(people$hc_first_name) == F]\n",
        "people$middle_name_extracted[is.na(people$hc_middle_name) == F] <- people$hc_middle_name[is.na(people$hc_middle_name) == F]\n",
        "people$last_name_extracted[is.na(people$hc_last_name) == F] <- people$hc_last_name[is.na(people$hc_last_name) == F]\n",
        "people$suffix_name_extracted[is.na(people$hc_suffix) == F] <- people$hc_suffix[is.na(people$hc_suffix) == F]\n",
        "\n",
        "# Correct names\n",
        "people$first_name <- people$first_name_extracted\n",
        "people$middle_name <- people$middle_name_extracted\n",
        "people$last_name <- people$last_name_extracted\n",
        "people$suffix_name <- people$suffix_name_extracted\n",
        "people <- unite(people, \"full_name\", c(first_name, middle_name, last_name, suffix_name), sep = \" \", na.rm = T, remove = F)\n",
        "people <- unite(people, \"full_name_first_last\", c(first_name, last_name), sep = \" \", na.rm = T, remove = F)\n",
        "people$full_name <- str_squish(people$full_name)\n",
        "people$full_name_first_last <- str_squish(people$full_name_first_last)\n",
        "\n",
        "# ----\n",
        "# CANDIDATE DESCRIPTIONS\n",
        "# Party\n",
        "people$party[!people$cand_party_affiliation %in% c(\"DEM\", \"REP\")] <- \"3rd party\"\n",
        "people$party[people$cand_party_affiliation == \"DEM\"] <- \"Democratic\"\n",
        "people$party[people$cand_party_affiliation == \"REP\"] <- \"Republican\"\n",
        "people$party[is.na(people$cand_party_affiliation)] <- NA\n",
        "\n",
        "# District number\n",
        "district_number <- as.character(as.numeric(people$cand_office_dist))\n",
        "district_number <- str_replace(district_number, \"$\", \"th\")\n",
        "district_number <- str_replace(district_number, \"1th\", \"1st\")\n",
        "district_number <- str_replace(district_number, \"2th\", \"2nd\")\n",
        "district_number <- str_replace(district_number, \"3th\", \"3rd\")\n",
        "district_number <- str_replace(district_number, \"11st\", \"11th\")\n",
        "district_number <- str_replace(district_number, \"12nd\", \"12th\")\n",
        "\n",
        "# State name rather than abbreviation\n",
        "state_name <- state.name[match(people$cand_office_st, state.abb)]\n",
        "\n",
        "# Construct the descriptions\n",
        "people$descr <- NA\n",
        "for (i in 1:nrow(people)) {\n",
        "  if (is.na(people$genelect_cd[i]) == F) {\n",
        "    if (people$cand_office[i] == \"H\") {\n",
        "      people$descr[i] <- paste0(people$full_name[i], \" is a \", people$party[i], \" candidate for the \", district_number[i], \" District of \", state_name[i], \".\")\n",
        "    } else if (people$cand_office[i] == \"S\") {\n",
        "      people$descr[i] <- paste0(people$full_name[i], \" is a \", people$party[i], \" Senate candidate in \", state_name[i], \".\")\n",
        "    }\n",
        "  } else if (people$currsen_2022[i] == 1) {\n",
        "    people$descr[i] <- paste0(people$full_name[i], \" is a Senator.\")\n",
        "  } else if (people$former_uspres[i] == 1) {\n",
        "    people$descr[i] <- paste0(people$full_name[i], \" is a former U.S. president.\")\n",
        "  } else if (people$prompol[i] == 1) {\n",
        "    people$descr[i] <- paste0(people$full_name[i], \" is a prominent politician.\")\n",
        "  } else if (people$intl_leaders[i] == 1) {\n",
        "    people$descr[i] <- paste0(people$full_name[i], \" is an international leader.\")\n",
        "  } else if (people$supcourt_2022[i] == 1) {\n",
        "    people$descr[i] <- paste0(people$full_name[i], \" is a Supreme Court Justice.\")\n",
        "  } else if (people$supcourt_former[i] == 1) {\n",
        "    people$descr[i] <- paste0(people$full_name[i], \" is a former Supreme Court Justice.\")\n",
        "  } else if (people$gov2022_gencd[i] == 1) {\n",
        "    people$descr[i] <- paste0(people$full_name[i], \" is a gubernatorial candidate.\")\n",
        "  } else if (people$pubhealth[i] == 1) {\n",
        "    people$descr[i] <- paste0(people$full_name[i], \" is a public health official.\")\n",
        "  } else if (people$cabinet[i] == 1) {\n",
        "    people$descr[i] <- paste0(people$full_name[i], \" is a cabinet member.\")\n",
        "  } else if (people$historical[i] == 1) {\n",
        "    people$descr[i] <- paste0(people$full_name[i], \" is a historical figure.\")\n",
        "  }\n",
        "}\n",
        "\n",
        "\n",
        "# ----\n",
        "# Candidate aliases\n",
        "for (i in 1:nrow(people)) {\n",
        "  cand_names <- c(people$full_name[i], people$last_name[i], people$full_name_first_last[i])\n",
        "  if (substr(cand_names[1], nchar(cand_names[1]), nchar(cand_names[1])) != \"s\") {\n",
        "    cand_aliases <- c(cand_names, paste0(cand_names, \"'s\"))\n",
        "  } else {\n",
        "    cand_aliases <- c(cand_names, paste0(cand_names, \"'\"))\n",
        "  }\n",
        "  cand_aliases <- c(cand_aliases, toupper(cand_aliases))\n",
        "\n",
        "  people$aliases[[i]] <- c(cand_aliases)\n",
        "}\n",
        "\n",
        "# ----\n",
        "# Create knowledge base\n",
        "kb <- people %>%\n",
        "  select(wmpid, full_name, descr, aliases) %>%\n",
        "  rename(id = wmpid, name = full_name)\n",
        "\n",
        "# One-off fixes\n",
        "kb$descr[kb$id == \"WMPID1289\"] <- \"Joe Biden is the U.S. president.\"\n",
        "kb$aliases[[1107]] <- str_remove(kb$aliases[[1107]], \",\") # Remove commas from MLK because it screws with the csv\n",
        "\n",
        "# Make sure every alias only exists once (people without middle names or suffixes will have duplicates otherwise)\n",
        "kb$aliases <- lapply(kb$aliases, unique)\n",
        "\n",
        "fwrite(kb, path_kb)\n",
        "# The 4 variables in this file are the only thing\n",
        "# from this script that enter the entity linker\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "slUEB4EI0OO4"
      },
      "source": [
        "# train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PCkuvW02DWbW"
      },
      "source": [
        "Steps to take before attempting to run train:\n",
        "\n",
        "- **Make sure that ```fb_2022_adid_text.csv.gz```, ```fb_2022_adid_var1.csv.gz```, ```entity_kb.csv``` and ```wmp_fb_2022_entities_v082324.csv``` are uploaded onto Google Drive. If they are not directly located in your main drive (e.g, they are in a folder) then the paths used in the code cells must be updated..**\n",
        "\n",
        "  - Files ```fb_2022_adid_text.csv.gz``` and ```fb_2022_adid_var1.csv.gz``` must be downloaded from our Figshare page. You can get access using this [Data Access form](https://www.creativewmp.com/data-access/).\n",
        "\n",
        "  - File [```entity_kb.csv```](https://github.com/Wesleyan-Media-Project/entity_linking_2022_usabilitystudy/blob/main/facebook/data/entity_kb.csv) will either already be present as output from the knowledge_base section, or you can download/upload it manually from the link provided. If it is present as output from the knowledge_base section then the path must be changed as specified in the code cells.\n",
        "\n",
        "  - File [```wmp_fb_2022_entities_v082324.csv```](https://github.com/Wesleyan-Media-Project/datasets/blob/main/wmp_entity_files/Facebook/wmp_fb_2022_entities_v082324.csv) can be downloaded/uploaded manually from the link provided"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NSebKtSX6M41"
      },
      "outputs": [],
      "source": [
        "!python3 -m spacy download en_core_web_lg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F7RBV2hdzhH5"
      },
      "outputs": [],
      "source": [
        "%%R\n",
        "library(data.table)\n",
        "library(dplyr)\n",
        "library(tidyr)\n",
        "\n",
        "setwd(\"./\")\n",
        "\n",
        "# Input files\n",
        "# This is an output from data-post-production/01-merge-results/01_merge_preprocessed_results\n",
        "# Select fields of 'ad_id', 'page_name', 'disclaimer', 'ad_creative_body',\n",
        "#        'ad_creative_link_caption', 'ad_creative_link_title',\n",
        "#        'ad_creative_link_description', 'aws_ocr_text_img',\n",
        "#        'google_asr_text', 'aws_ocr_text_vid'\n",
        "#############################################################################################\n",
        "\n",
        "# Make sure that these files are in the colab environment before attempting to run\n",
        "\n",
        "path_ads <- \"/content/drive/MyDrive/fb_2022_adid_text.csv.gz\"\n",
        "path_adid_to_pageid <- \"/content/drive/MyDrive/fb_2022_adid_var1.csv.gz\"\n",
        "\n",
        "# If you ran the knowledge_base section, this path must be changed to \"/content/entity_kb.csv\"\n",
        "path_entities_kb <- \"/content/drive/MyDrive/entity_kb.csv\"\n",
        "\n",
        "# This file is located in our datasets repository (https://github.com/Wesleyan-Media-Project/datasets)\n",
        "# Make sure that these files are uploaded into the colab environment before attempting to run\n",
        "\n",
        "path_wmpent_file <- \"/content/drive/MyDrive/wmp_fb_2022_entities_v082324.csv\" # nolint: line_length_linter.\n",
        "# Output files\n",
        "path_output <- \"ads_with_aliases.csv.gz\"\n",
        "\n",
        "# Pdid to wmpid\n",
        "wmpents <- fread(path_wmpent_file) %>%\n",
        "  select(pd_id, wmpid)\n",
        "wmpents <- wmpents[wmpents$wmpid != \"\", ]\n",
        "\n",
        "# Ads\n",
        "df <- fread(path_ads, encoding = \"UTF-8\")\n",
        "\n",
        "cols <- c(\n",
        "  \"ad_id\", \"page_name\", \"disclaimer\", \"ad_creative_body\", \"ad_creative_link_caption\", \"ad_creative_link_title\",\n",
        "  \"ad_creative_link_description\", \"aws_ocr_text_img\", \"google_asr_text\", \"aws_ocr_text_vid\"\n",
        ") # nolint\n",
        "# Select only the specified columns\n",
        "df <- df[, ..cols]\n",
        "\n",
        "# Adid to pdid\n",
        "adid_to_pageid <-\n",
        "  fread(path_adid_to_pageid, colClasses = \"character\") %>%\n",
        "  select(ad_id, pd_id)\n",
        "\n",
        "# Combine\n",
        "df <- inner_join(df, adid_to_pageid, by = \"ad_id\")\n",
        "df <- left_join(df, wmpents, by = \"pd_id\")\n",
        "\n",
        "# Aliases, then merge in pd_id\n",
        "aliases <- fread(path_entities_kb, encoding = \"UTF-8\", data.table = F)\n",
        "aliases <- select(aliases, c(id, aliases))\n",
        "\n",
        "# Keep only ads that have a wmpid\n",
        "# Shape to long format\n",
        "# Remove empty rows\n",
        "# Keep only distinct rows based on pd_id and value\n",
        "df <- df %>%\n",
        "  filter(wmpid != \"\") %>%\n",
        "  pivot_longer(-c(ad_id, pd_id, wmpid)) %>%\n",
        "  filter(value != \"\") %>%\n",
        "  distinct_at(vars(pd_id, value), .keep_all = T)\n",
        "\n",
        "# Merge in aliases\n",
        "df <- left_join(df, aliases, by = c(\"wmpid\" = \"id\"))\n",
        "\n",
        "# Get rid of ads that have no aliases\n",
        "df <- df[is.na(df$aliases) == F, ]\n",
        "\n",
        "fwrite(df, path_output)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pP7a8kkdzzXC"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "from pathlib import Path\n",
        "import os\n",
        "import random\n",
        "import json\n",
        "import pandas as pd\n",
        "import spacy # Use version 3.2.4\n",
        "nlp = spacy.load(\"en_core_web_lg\")\n",
        "from spacy.kb import KnowledgeBase #vscode pylinter complains, actually loads fine\n",
        "# for spacy version above v3.5\n",
        "# from spacy.kb import InMemoryLookupKB\n",
        "from spacy.util import minibatch, compounding\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "from spacy.training import Example\n",
        "from spacy.ml.models import load_kb\n",
        "\n",
        "\n",
        "# Input files\n",
        "# Make sure that these files are in the colab environment before attempting to run\n",
        "\n",
        "# If you ran the knowledge_base section, this path must be changed to \"/content/entity_kb.csv\"\n",
        "path_candidates = \"/content/drive/MyDrive/entity_kb.csv\"\n",
        "\n",
        "path_training_samples = \"/content/ads_with_aliases.csv.gz\"\n",
        "\n",
        "# Output files\n",
        "path_intermediate_kb = \"intermediate_kb\"\n",
        "path_output_nlp = \"trained_entity_linker\"\n",
        "path_output_kb = \"trained_entity_linker\"\n",
        "path_output_kb_vocab = \"trained_entity_linker\"\n",
        "\n",
        "\n",
        "#----\n",
        "# Load the dataset on the candidates\n",
        "# This contains their id, their name, a description, and aliases for their name\n",
        "\n",
        "def load_entities():\n",
        "    entities_loc = Path(path_candidates)\n",
        "\n",
        "    names = dict()\n",
        "    descriptions = dict()\n",
        "    aliases = dict()\n",
        "    with entities_loc.open(\"r\", encoding=\"utf8\") as csvfile:\n",
        "        csvreader = csv.reader(csvfile, delimiter=\",\")\n",
        "        next(csvreader) # Skip header row\n",
        "        for row in csvreader:\n",
        "            qid = row[0]\n",
        "            name = row[1]\n",
        "            desc = row[2]\n",
        "            alias = row[3]\n",
        "            names[qid] = name\n",
        "            descriptions[qid] = desc\n",
        "            aliases[qid] = alias\n",
        "    return names, descriptions, aliases\n",
        "\n",
        "# Create 3 dictionaries:\n",
        "# name_dict - ID -> name\n",
        "# desc_dict - ID -> description\n",
        "# aliases_dict - ID -> aliases\n",
        "name_dict, desc_dict, aliases_dict = load_entities()\n",
        "\n",
        "# Example content for Biden:\n",
        "print(f\"{'WMPID1289'}, name={name_dict['WMPID1289']}, \\\n",
        "    desc={desc_dict['WMPID1289']}, alias={aliases_dict['WMPID1289']}\")\n",
        "\n",
        "#----\n",
        "# Create a knowledge base\n",
        "# So far, information on these people sits in a set of dictionaries\n",
        "# Now we create a spacy knowledge base and populate it with the data above\n",
        "\n",
        "# Instantiate a knowledge base with 300-dimensional entity embedding\n",
        "# for spacy version above v3.5, instantiate the InMemoryLookupKB class instead of KnowledgeBase, which became an abstract class after v3.5\n",
        "kb = KnowledgeBase(vocab=nlp.vocab, entity_vector_length=300)\n",
        "\n",
        "# Populate the knowledge base from the csv file\n",
        "# Starting with the id and description\n",
        "for qid, desc in desc_dict.items():\n",
        "    desc_doc = nlp(desc)\n",
        "    desc_enc = desc_doc.vector\n",
        "    kb.add_entity(entity=qid, entity_vector=desc_enc, freq=342) # 342 is an arbitrary value\n",
        "\n",
        "# Create a dictionary, with each unique alias as a key\n",
        "# and the value being the fecids of all the people with that alias as a list\n",
        "alias_to_fecids = dict()\n",
        "for qid, alias in aliases_dict.items():\n",
        "    for alias_specific in alias.split(\"|\"):\n",
        "        alias_to_fecids[alias_specific] = alias_to_fecids.get(alias_specific, []) + [qid]\n",
        "\n",
        "# Now, start adding aliases to the kb\n",
        "# The probabiltiy is 1/number of people with that alias\n",
        "for alias, fecids in alias_to_fecids.items():\n",
        "    kb.add_alias(alias=alias, entities=fecids, probabilities=[1/len(fecids) for fecid in fecids])\n",
        "\n",
        "# Create a list of entity ids (i.e. fec ids in our case) that is looped over later\n",
        "qids = name_dict.keys()\n",
        "kb.to_disk(path_intermediate_kb)\n",
        "\n",
        "\n",
        "#----\n",
        "df = pd.read_csv(path_training_samples, encoding = 'UTF-8')\n",
        "aliases = list(df['aliases'].str.split(\"|\"))\n",
        "\n",
        "# Apply NER to all training samples\n",
        "TRAIN_DOCS = []\n",
        "for text in tqdm(df['value']):\n",
        "    doc = nlp(text)\n",
        "    TRAIN_DOCS.append(doc)\n",
        "\n",
        "# Put the character indices in the data frame\n",
        "df['entity_start'] = np.nan\n",
        "df['entity_end'] = np.nan\n",
        "# Loop over the documents\n",
        "# and record the indices from the NER results in the df\n",
        "for d in range(len(TRAIN_DOCS)):\n",
        "    for entity in TRAIN_DOCS[d].ents:\n",
        "        if str(entity) in aliases[d]:\n",
        "            print([entity, entity.start_char, entity.end_char])\n",
        "            df.at[d, 'entity_start'] = entity.start_char\n",
        "            df.at[d, 'entity_end'] = entity.end_char\n",
        "            break\n",
        "\n",
        "\n",
        "# Get the indices of the rows of the data frame where an entity match was detected\n",
        "detected_entities_indices = np.where(df['entity_start'].isnull().to_numpy()==False)[0]\n",
        "detected_entities_indices = list(detected_entities_indices)\n",
        "\n",
        "# Make a new TRAIN_DOCS list with only those\n",
        "TRAIN_DOCS2 = [TRAIN_DOCS[i] for i in detected_entities_indices]\n",
        "print(\"Training on\", len(TRAIN_DOCS2), \"samples.\") #currently about 14k (out of 60k)\n",
        "\n",
        "# Create the annotations like this\n",
        "# {'links': {(39, 48): {'H8MO01143': 1.0}}}\n",
        "starts = [int(df['entity_start'][i]) for i in detected_entities_indices]\n",
        "ends = [int(df['entity_end'][i]) for i in detected_entities_indices]\n",
        "fecs = [df['wmpid'][i] for i in detected_entities_indices]\n",
        "# print(starts, ends, fecs)\n",
        "\n",
        "annotations = []\n",
        "for i in range(len(starts)):\n",
        "    annotations.append({'links': {(starts[i], ends[i]): {fecs[i]: 1.0}}, 'entities': [(starts[i], ends[i], 'PERSON')]})\n",
        "\n",
        "# Make another version of TRAIN_DOCS, this time making it the correct tuple again,\n",
        "#  with annotations as the second element\n",
        "TRAIN_DOCS3 = []\n",
        "for i in range(len(starts)):\n",
        "    TRAIN_DOCS3.append((TRAIN_DOCS2[i], annotations[i]))\n",
        "\n",
        "# Create gold-standard sentences\n",
        "if \"sentencizer\" not in nlp.pipe_names:\n",
        "    nlp.add_pipe(\"sentencizer\")\n",
        "sentencizer = nlp.get_pipe(\"sentencizer\")\n",
        "TRAIN_EXAMPLES = []\n",
        "for i in range(len(starts)):\n",
        "    example = Example.from_dict(nlp.make_doc(str(TRAIN_DOCS3[i][0])), annotations[i])\n",
        "    example.reference = sentencizer(example.reference)\n",
        "    TRAIN_EXAMPLES.append(example)\n",
        "\n",
        "# Initialize the entity linker component\n",
        "entity_linker = nlp.add_pipe(\"entity_linker\", config={\"incl_prior\": False}, last=True)\n",
        "entity_linker.initialize(get_examples=lambda: TRAIN_EXAMPLES, kb_loader=load_kb(path_intermediate_kb))\n",
        "\n",
        "# At this point, the untrained component already works\n",
        "test_doc = nlp(\"Donald Trump is a former president.\")\n",
        "for ent in test_doc.ents:\n",
        "    if ent.kb_id_ != 'NIL':\n",
        "        print(ent.kb_id_)\n",
        "\n",
        "\n",
        "# Training loop\n",
        "loss_list = []\n",
        "with nlp.select_pipes(enable=[\"entity_linker\"]):   # train only the entity_linker\n",
        "    optimizer = nlp.resume_training() # This used to be begin_training, in spacy3 it seems it's resume because the component has already been initialized\n",
        "    optimizer.learn_rate = 0.001\n",
        "    for itn in tqdm(range(500)):   # one itn is one full pass over TRAIN_EXAMPLES\n",
        "        random.shuffle(TRAIN_EXAMPLES)\n",
        "        batches = minibatch(TRAIN_EXAMPLES, size=128)#size=compounding(4.0, 32.0, 1.001))  # increasing batch sizes -- seems to train WAY faster with a larger batch size (i.e. 128 rather than 32)\n",
        "        losses = {} #at the end of the epoch, this will contain the cumulative loss of all of its batches (and as far as I can tell, the loss for one batch is the mean loss of all the samples in it)\n",
        "        for batch in batches:\n",
        "            nlp.update(\n",
        "                batch,\n",
        "                drop=0.2,      # prevent overfitting\n",
        "                losses=losses,\n",
        "                sgd=optimizer,\n",
        "            )\n",
        "        #if itn % 50 == 0:\n",
        "        print(itn, \"Losses\", losses)   # print the training loss\n",
        "        loss_list.append(losses['entity_linker'])\n",
        "\n",
        "print(itn, \"Losses\", losses)\n",
        "\n",
        "# Save the nlp object to file\n",
        "nlp.to_disk(path_output_nlp)\n",
        "kb.to_disk(path_output_kb)\n",
        "kb.vocab.to_disk(path_output_kb_vocab)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oQlL8jsLzYVa"
      },
      "source": [
        "# inference"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3UJEsAJbGAiX"
      },
      "source": [
        "Steps to take before attempting to run inference:\n",
        "\n",
        "- ***IF YOU ARE PART OF THE USABILITY STUDY YOU CAN SKIP THESE INSTRUCTIONS, AS YOU'LL DOWNLOAD THE FILES IN THE CODE.***\n",
        "\n",
        "- **Make sure that ```fb_2022_adid_text.csv.gz``` and ```trained_entity_linker``` are uploaded onto Google Drive. If they are not directly located in your main drive (e.g, they are in a folder) then the paths used in the code cells must be updated.**\n",
        "\n",
        "  - File ```fb_2022_adid_text.csv.gz``` will either already be present from running the train section, or else it must be downloaded from our Figshare page and then uploaded manually. You can get access using this [Data Access form](https://www.creativewmp.com/data-access/). If it is present as output from the train section, then you must update the path in the code cell as specified.\n",
        "\n",
        "  - Folder ```trained_entity_linker``` will either already be present as output from the train section, or else it must be downloaded from our Figshare page and then uploaded manually **as a zip file**. You can get access using this [Data Access form](https://www.creativewmp.com/data-access/). If it is present as output from the train section, then you must change the path in the code cell as specified.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Direct download of fb_2022_adid_text.csv.gz\n",
        "!wget -O fb_2022_adid_text.csv.gz https://figshare.com/ndownloader/files/49885527?private_link=c46dc366bbf4294a9be3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-5WrTxvSnZT5",
        "outputId": "01bb4962-0be2-4730-ea61-fbb5f7ad5830"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-12-05 20:56:19--  https://figshare.com/ndownloader/files/49885527?private_link=c46dc366bbf4294a9be3\n",
            "Resolving figshare.com (figshare.com)... 52.209.26.118, 34.251.104.172, 2a05:d018:1f4:d003:d8b9:f7a:320e:85ca, ...\n",
            "Connecting to figshare.com (figshare.com)|52.209.26.118|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://s3-eu-west-1.amazonaws.com/pstorage-wesleyan-1795779948/49885527/fb_2022_adid_text.csv.gz?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIA3OGA3B5WKAYJ2FVS/20241205/eu-west-1/s3/aws4_request&X-Amz-Date=20241205T205620Z&X-Amz-Expires=10&X-Amz-SignedHeaders=host&X-Amz-Signature=fb1471c8dd8b6145f93315e47ec68d2f7aafc0839de18de963d5959080bec746 [following]\n",
            "--2024-12-05 20:56:20--  https://s3-eu-west-1.amazonaws.com/pstorage-wesleyan-1795779948/49885527/fb_2022_adid_text.csv.gz?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIA3OGA3B5WKAYJ2FVS/20241205/eu-west-1/s3/aws4_request&X-Amz-Date=20241205T205620Z&X-Amz-Expires=10&X-Amz-SignedHeaders=host&X-Amz-Signature=fb1471c8dd8b6145f93315e47ec68d2f7aafc0839de18de963d5959080bec746\n",
            "Resolving s3-eu-west-1.amazonaws.com (s3-eu-west-1.amazonaws.com)... 52.218.116.216, 52.218.93.35, 52.218.100.211, ...\n",
            "Connecting to s3-eu-west-1.amazonaws.com (s3-eu-west-1.amazonaws.com)|52.218.116.216|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 103037523 (98M) [application/gzip]\n",
            "Saving to: ‘fb_2022_adid_text.csv.gz’\n",
            "\n",
            "fb_2022_adid_text.c 100%[===================>]  98.26M  22.8MB/s    in 5.2s    \n",
            "\n",
            "2024-12-05 20:56:26 (19.0 MB/s) - ‘fb_2022_adid_text.csv.gz’ saved [103037523/103037523]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "8j5HV0-EeUqc",
        "outputId": "b9ccbb2e-0880-4a9b-b0a4-17c9217f9672",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: data.table 1.16.2 using 1 threads (see ?getDTthreads).  \n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: Latest news: r-datatable.com\n",
            "\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: \n",
            "Attaching package: ‘dplyr’\n",
            "\n",
            "\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: The following objects are masked from ‘package:data.table’:\n",
            "\n",
            "    between, first, last\n",
            "\n",
            "\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: The following objects are masked from ‘package:stats’:\n",
            "\n",
            "    filter, lag\n",
            "\n",
            "\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: The following objects are masked from ‘package:base’:\n",
            "\n",
            "    intersect, setdiff, setequal, union\n",
            "\n",
            "\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: |--------------------------------------------------|\n",
            "|\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: =\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: |\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": []
        }
      ],
      "source": [
        "%%R\n",
        "\n",
        "library(data.table)\n",
        "library(dplyr)\n",
        "library(tidyr)\n",
        "\n",
        "setwd(\"./\")\n",
        "\n",
        "# Input files\n",
        "# This is an output from data-post-production/01-merge-results/01_merge_preprocessed_results.\n",
        "# Make sure that this file is in the colab environment before attempting to run\n",
        "\n",
        "# If you ran the train, this path must be changed to \"/content/fb_2022_adid_text.csv.gz\"\n",
        "path_ads <- \"/content/fb_2022_adid_text.csv.gz\"\n",
        "# Output files\n",
        "path_prepared_ads <- \"inference_all_fb22_ads.csv.gz\"\n",
        "\n",
        "# Ads\n",
        "df <- fread(path_ads, encoding = \"UTF-8\")\n",
        "\n",
        "# Subset to clean text dataframe\n",
        "df2 <- df %>%\n",
        "  select(\n",
        "    ad_id, google_asr_text, page_name, disclaimer, ad_creative_body,\n",
        "    ad_creative_link_title, ad_creative_link_description,\n",
        "    aws_ocr_text_img, aws_ocr_text_vid, ad_creative_link_caption\n",
        "  )\n",
        "\n",
        "# Aggregate\n",
        "df3 <- df2 %>%\n",
        "  pivot_longer(-ad_id) %>%\n",
        "  filter(value != \"\") %>%\n",
        "  mutate(id = paste(ad_id, name, sep = \"__\")) %>%\n",
        "  select(-c(ad_id, name))\n",
        "\n",
        "df3 <- aggregate(df3$id, by = list(df3$value), c)\n",
        "names(df3) <- c(\"text\", \"id\")\n",
        "\n",
        "# Save\n",
        "fwrite(df3, path_prepared_ads)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "pnd2zRqTjdPo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b66874db-693e-45d0-c437-871aa7a4e53f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-12-05 21:01:53--  https://figshare.wesleyan.edu/ndownloader/files/46512400\n",
            "Resolving figshare.wesleyan.edu (figshare.wesleyan.edu)... 52.209.26.118, 34.251.104.172, 2a05:d018:1f4:d003:d8b9:f7a:320e:85ca, ...\n",
            "Connecting to figshare.wesleyan.edu (figshare.wesleyan.edu)|52.209.26.118|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://s3-eu-west-1.amazonaws.com/pstorage-wesleyan-1795779948/46512400/trained_entity_linker.zip?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIA3OGA3B5WKAYJ2FVS/20241205/eu-west-1/s3/aws4_request&X-Amz-Date=20241205T210153Z&X-Amz-Expires=10&X-Amz-SignedHeaders=host&X-Amz-Signature=2c39413ed965b36e1f5b37733c9a424129682cde5083a2d5faa2f0e590a2054d [following]\n",
            "--2024-12-05 21:01:54--  https://s3-eu-west-1.amazonaws.com/pstorage-wesleyan-1795779948/46512400/trained_entity_linker.zip?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIA3OGA3B5WKAYJ2FVS/20241205/eu-west-1/s3/aws4_request&X-Amz-Date=20241205T210153Z&X-Amz-Expires=10&X-Amz-SignedHeaders=host&X-Amz-Signature=2c39413ed965b36e1f5b37733c9a424129682cde5083a2d5faa2f0e590a2054d\n",
            "Resolving s3-eu-west-1.amazonaws.com (s3-eu-west-1.amazonaws.com)... 52.218.57.91, 52.92.20.152, 52.92.20.224, ...\n",
            "Connecting to s3-eu-west-1.amazonaws.com (s3-eu-west-1.amazonaws.com)|52.218.57.91|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1550796978 (1.4G) [application/zip]\n",
            "Saving to: ‘trained_entity_linker.zip’\n",
            "\n",
            "trained_entity_link 100%[===================>]   1.44G  26.0MB/s    in 59s     \n",
            "\n",
            "2024-12-05 21:02:53 (25.0 MB/s) - ‘trained_entity_linker.zip’ saved [1550796978/1550796978]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Direct download of trained_entity_linker.zip\n",
        "\n",
        "# Download the file\n",
        "!wget -O trained_entity_linker.zip https://figshare.wesleyan.edu/ndownloader/files/46512400\n",
        "\n",
        "# Unzip the file\n",
        "import os\n",
        "import zipfile\n",
        "\n",
        "zip_path = \"trained_entity_linker.zip\"\n",
        "\n",
        "# Extract the contents\n",
        "!unzip trained_entity_linker.zip\n",
        "\n",
        "# Remove the __MACOSX folder if it exists\n",
        "if os.path.exists(\"__MACOSX\"):\n",
        "    !rm -rf __MACOSX/\n",
        "    print(\"__MACOSX folder removed.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "jL_dPqk3gPmf",
        "outputId": "02ede874-022e-451d-a32e-d1e00ee0382b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/__init__.py:1144: UserWarning: torch.set_default_tensor_type() is deprecated as of PyTorch 2.1, please use torch.set_default_dtype() and torch.set_default_device() as alternatives. (Triggered internally at ../torch/csrc/tensor/python_tensor.cpp:432.)\n",
            "  _C._set_default_tensor_type(t)\n",
            "100%|██████████| 500/500 [00:23<00:00, 21.13it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "text done!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing rows: 100%|██████████| 428/428 [00:00<00:00, 3962.73it/s]\n"
          ]
        }
      ],
      "source": [
        "import csv\n",
        "from pathlib import Path\n",
        "import os\n",
        "import random\n",
        "import json\n",
        "import pandas as pd\n",
        "import spacy # Use version '3.2.4'\n",
        "# Make sure that this file is in the colab environment before attempting to run\n",
        "# If you ran the knowledge_base section, this path must be changed to \"/content/trained_entity_linker.zip\"\n",
        "nlp = spacy.load(\"/content/trained_entity_linker\") # trained_entity_linker is output from 02_train_entity_linking.py\n",
        "from spacy.kb import KnowledgeBase #vscode pylinter complains about this, but it actually loads fine\n",
        "from spacy.util import minibatch, compounding\n",
        "import re\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "# Input files\n",
        "path_prepared_ads = \"/content/inference_all_fb22_ads.csv.gz\"\n",
        "# Output files\n",
        "path_el_results = \"entity_linking_results_fb22.csv.gz\"\n",
        "path_el_results_notext = \"entity_linking_results_fb22_notext.csv.gz\"\n",
        "\n",
        "# Read in prepared ads\n",
        "df = pd.read_csv(path_prepared_ads)\n",
        "\n",
        "# Code below runs a random sample of rows from the input dataframe,\n",
        "# where n equals the # of rows\n",
        "\n",
        "df = df.sample(n=500)\n",
        "df = df.reset_index(drop=True)\n",
        "\n",
        "\n",
        "df = df.replace(np.nan, '', regex=True)\n",
        "fields = ['text']\n",
        "\n",
        "\n",
        "def get_sims(sent_emb, ent_id):\n",
        "\n",
        "    sentence_encoding = sent_emb\n",
        "    entity_encodings = np.asarray(nlp.get_pipe('entity_linker').kb.get_vector(ent_id))\n",
        "\n",
        "    sentence_norm = np.linalg.norm(sentence_encoding, axis=0)\n",
        "    entity_norm = np.linalg.norm(entity_encodings, axis=0)\n",
        "\n",
        "    sims = np.dot(entity_encodings, sentence_encoding) / (sentence_norm * entity_norm)\n",
        "\n",
        "    return(sims)\n",
        "\n",
        "# Give non-candidates like Kamala Harris a boost in comparison to actual cands\n",
        "# This is necessary because non-cands don't have much training data, so the model\n",
        "# almost never picks them\n",
        "def is_it_kamala(nlpd_doc, possible_cands, likely_cand, boost_size = 0.1):\n",
        "\n",
        "    sent_emb = nlpd_doc.vector\n",
        "\n",
        "    sims = []\n",
        "    for h in possible_cands:\n",
        "\n",
        "        sim = get_sims(sent_emb, h)\n",
        "        if h == likely_cand:\n",
        "            sim += boost_size\n",
        "\n",
        "        sims.append(sim)\n",
        "\n",
        "    picked_cand = np.array(sims).argmax()\n",
        "    picked_cand_id = possible_cands[picked_cand]\n",
        "\n",
        "    return(picked_cand_id)\n",
        "\n",
        "harrises = ['WMPID1144',\n",
        "            'WMPID3207',\n",
        "            'WMPID2']\n",
        "\n",
        "barretts = ['WMPID3995',\n",
        "            'WMPID17']\n",
        "\n",
        "\n",
        "# This loop can take anywhere from 6-8 hours.\n",
        "\n",
        "for f in fields:\n",
        "\n",
        "    entities_in_field = []\n",
        "    entities_in_field_start = []\n",
        "    entities_in_field_end = []\n",
        "\n",
        "    for i in tqdm(range(len(df))):\n",
        "\n",
        "        entities_in_ad = []\n",
        "        entities_in_ad_start = []\n",
        "        entities_in_ad_end = []\n",
        "\n",
        "        if pd.isnull(df[f][i])==False:\n",
        "            test_text = df[f][i]\n",
        "            test_doc = nlp(test_text)\n",
        "            for ent in test_doc.ents:\n",
        "                if ent.kb_id_ != 'NIL':\n",
        "\n",
        "                    # Make sure we don't misclassify House as Steve House\n",
        "                    # Steve House didn't run in 2022 \\o/ yay!\n",
        "                    # if (ent.kb_id_ == 'H0CO06119') & (ent.label_ == 'ORG'):\n",
        "                    #     pass\n",
        "\n",
        "                    # Make sure we don't misclassify Kamala as one of the other Harrises\n",
        "                    if ent.kb_id_ in harrises:\n",
        "                        # Check if it is actually Kamala\n",
        "                        harrises_cand = is_it_kamala(test_doc, harrises, 'WMPID2', boost_size = 0.16)\n",
        "                        entities_in_ad.append(harrises_cand)\n",
        "                        entities_in_ad_start.append(ent.start_char)\n",
        "                        entities_in_ad_end.append(ent.end_char)\n",
        "\n",
        "                    # Make sure we don't misclassify Amy Coney Barrett as Thomas More Barrett\n",
        "                    # If the EL detects Thomas More Barrett\n",
        "                    elif ent.kb_id_ == 'WMPID3995':\n",
        "                        # Check if it is actually Amy Coney\n",
        "                        barretts_cand = is_it_kamala(test_doc, barretts, 'WMPID17', boost_size = 0.17)\n",
        "                        entities_in_ad.append(barretts_cand)\n",
        "                        entities_in_ad_start.append(ent.start_char)\n",
        "                        entities_in_ad_end.append(ent.end_char)\n",
        "\n",
        "                    # If it is none of these, proceed as normal\n",
        "                    else:\n",
        "                        entities_in_ad.append(ent.kb_id_)\n",
        "                        entities_in_ad_start.append(ent.start_char)\n",
        "                        entities_in_ad_end.append(ent.end_char)\n",
        "\n",
        "        entities_in_field.append(entities_in_ad)\n",
        "        entities_in_field_start.append(entities_in_ad_start)\n",
        "        entities_in_field_end.append(entities_in_ad_end)\n",
        "\n",
        "\n",
        "    df[f + '_detected_entities'] = entities_in_field\n",
        "    df[f + '_start'] = entities_in_field_start\n",
        "    df[f + '_end'] = entities_in_field_end\n",
        "\n",
        "    print(f, \"done!\")\n",
        "\n",
        "## Prepare data for additional dictionary search for Trump and Biden only on disclaimer and page name fields\n",
        "# Split ids\n",
        "df['id'] = df['id'].str.split('|')\n",
        "# \"Un-deduplicate\", or \"Re-hydrate\", in WMP lingo\n",
        "df = df.explode('id')\n",
        "# Split into ad id and field\n",
        "df_ids = df['id'].str.split('__', expand = True)\n",
        "df_ids.columns = ['ad_id', 'field']\n",
        "df = pd.concat([df, df_ids], axis = 1)\n",
        "df = df.drop(labels = ['id'], axis = 1)\n",
        "# Split the data frame into disclaimer/page_name, and other\n",
        "df_1 = df[df['field'].isin(['disclaimer', 'page_name'])]\n",
        "df_2 = df[df['field'].isin(['disclaimer', 'page_name']) == False]\n",
        "# Make a copy of df_1\n",
        "df1 = df_1.copy()\n",
        "df1.reset_index(drop=True, inplace=True)\n",
        "\n",
        "# This function does a simple dictionary search on disclaimer and page name fields.\n",
        "# It only does this search for Biden and Trump.\n",
        "# If this dictionary search finds any entity that was not detected by the model, it adds the corresponding WMPID to the detected entities list.\n",
        "\n",
        "def update_detected_entities(df):\n",
        "    # Mapping of names to their corresponding ids\n",
        "    name_to_id = {'biden': 'WMPID1289', 'trump': 'WMPID1290'}\n",
        "    # Iterate over each row in the DataFrame with tqdm\n",
        "    for index, row in tqdm(df.iterrows(), total=len(df), desc=\"Processing rows\"):\n",
        "        # Split the text_detected_entities column to a list\n",
        "        detected_entities = row['text_detected_entities']\n",
        "\n",
        "        # Initialize lists to store start and end indices\n",
        "        start_indices = row['text_start']\n",
        "        end_indices = row['text_end']\n",
        "\n",
        "        # Convert the text to lowercase\n",
        "        text = row['text'].lower()\n",
        "\n",
        "        # Iterate over each name to be detected\n",
        "        for name in name_to_id.keys():\n",
        "            # Find all occurrences of the name in the text\n",
        "            name_occurrences = [i for i in range(len(text)) if text.startswith(name, i)]\n",
        "\n",
        "            # Check each occurrence of the name\n",
        "            for start_index in name_occurrences:\n",
        "                # Check if the name is already detected by the entity linking model\n",
        "                already_detected = False\n",
        "                for start, end in zip(start_indices, end_indices):\n",
        "                    if start <= start_index < end:\n",
        "                        already_detected = True\n",
        "                        break\n",
        "\n",
        "                # If the name is not already detected, add its ID\n",
        "                if not already_detected:\n",
        "                    end_index = start_index + len(name)\n",
        "                    detected_entities.append(name_to_id[name])\n",
        "                    start_indices.append(start_index)\n",
        "                    end_indices.append(end_index)\n",
        "\n",
        "        # Update the DataFrame with the modified lists\n",
        "        df.at[index, 'text_detected_entities'] = detected_entities\n",
        "        df.at[index, 'text_start'] = start_indices\n",
        "        df.at[index, 'text_end'] = end_indices\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "df2 = update_detected_entities(df1)\n",
        "\n",
        "\n",
        "# Recombine the dataframes\n",
        "df = pd.concat([df2, df_2], axis = 0)\n",
        "\n",
        "# Save results\n",
        "df.to_csv(path_el_results, index=False)\n",
        "df = df.drop(['text'], axis = 1)\n",
        "df.to_csv(path_el_results_notext, index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "8yKaYoRYj3Jt"
      },
      "outputs": [],
      "source": [
        "# Post-processing for the entity linking results\n",
        "# Gather up all detected entities from different fields and put them all together\n",
        "\n",
        "%%R\n",
        "\n",
        "library(data.table)\n",
        "library(dplyr)\n",
        "library(tidyr)\n",
        "library(stringr)\n",
        "\n",
        "setwd(\"./\")\n",
        "\n",
        "# Paths\n",
        "# In\n",
        "path_detected_entities <- \"/content/entity_linking_results_fb22_notext.csv.gz\"\n",
        "# Out\n",
        "path_finished_enties <- \"detected_entities_fb22.csv.gz\"\n",
        "path_finished_enties_for_ad_tone <- \"detected_entities_fb22_for_ad_tone.csv.gz\"\n",
        "\n",
        "# Read in Spacy's detected entities\n",
        "el <- fread(path_detected_entities)\n",
        "\n",
        "# Transform the Python-based detected entities field into an R list\n",
        "transform_pylist <- function(x) {\n",
        "  x <- str_remove_all(x, \"\\\\[|\\\\]|\\\\'\")\n",
        "  x <- str_remove_all(x, \" \")\n",
        "  return(x)\n",
        "}\n",
        "el$text_detected_entities <- transform_pylist(el$text_detected_entities)\n",
        "# Remove all ads with no detected entities\n",
        "el <- el %>% filter(text_detected_entities != \"\")\n",
        "# For ad tone, remove disclaimer and page_name\n",
        "el_at <- el %>% filter(!field %in% c(\"page_name\", \"disclaimer\"))\n",
        "# Aggregate over fields, then clean up and put things back into a list\n",
        "el <- aggregate(el$text_detected_entities, by = list(el$ad_id), c)\n",
        "el$x <- lapply(el$x, paste, collapse = \",\")\n",
        "el$x <- str_split(el$x, \",\")\n",
        "names(el) <- c(\"ad_id\", \"detected_entities\")\n",
        "# Same for ad tone\n",
        "el_at <- aggregate(el_at$text_detected_entities, by = list(el_at$ad_id), c)\n",
        "el_at$x <- lapply(el_at$x, paste, collapse = \",\")\n",
        "el_at$x <- str_split(el_at$x, \",\")\n",
        "names(el_at) <- c(\"ad_id\", \"detected_entities\")\n",
        "\n",
        "# Save version with combined fields\n",
        "fwrite(el, path_finished_enties)\n",
        "fwrite(el_at, path_finished_enties_for_ad_tone)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "FPtw0zahIaE6",
        "outputId": "2a66bfa9-8fc7-4935-bdb1-e67ba794ae8e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                 ad_id                                  detected_entities\n",
              "0   x_1004064094349321                                          WMPID5324\n",
              "1   x_1014790769921103                                          WMPID5311\n",
              "2   x_1015736559308167                                          WMPID1289\n",
              "3   x_1030753497615500            WMPID5288|WMPID5288|WMPID5288|WMPID5288\n",
              "4   x_1035272853805340                                WMPID5206|WMPID5206\n",
              "5   x_1042674793114285  WMPID4125|WMPID4125|WMPID4125|WMPID1289|WMPID4...\n",
              "6   x_1047779595902145                                          WMPID5311\n",
              "7   x_1066648220639547                                          WMPID1289\n",
              "8   x_1069861830399015                      WMPID1069|WMPID1069|WMPID1069\n",
              "9   x_1070531630300440                                          WMPID3765\n",
              "10  x_1075816219803458                                          WMPID5311\n",
              "11  x_1076667379659593                                          WMPID5311\n",
              "12  x_1080800939304636                                    WMPID21|WMPID21\n",
              "13  x_1082386059310872                                          WMPID4511\n",
              "14  x_1083276702372073                                          WMPID5311\n",
              "15  x_1083642688983769                                          WMPID5339\n",
              "16  x_1086972378677092                                          WMPID5311\n",
              "17  x_1087942005205168  WMPID4125|WMPID4125|WMPID4125|WMPID1289|WMPID4...\n",
              "18  x_1088126968505263                                          WMPID3765\n",
              "19  x_1088346575218148                                          WMPID5334\n",
              "20  x_1089616945280729  WMPID4308|WMPID4308|WMPID4308|WMPID4308|WMPID4...\n",
              "21  x_1090717081582950                                          WMPID5311\n",
              "22  x_1091640268379977  WMPID4125|WMPID4125|WMPID4125|WMPID1289|WMPID4...\n",
              "23  x_1094882458083956                                          WMPID3388\n",
              "24  x_1103395850571337                                          WMPID4511\n",
              "25  x_1104384606931179                                          WMPID5334\n",
              "26  x_1105871176716617                                          WMPID3765\n",
              "27  x_1106120006979848                                          WMPID5311\n",
              "28  x_1107268893319851                                          WMPID5341\n",
              "29  x_1109228639727522                                          WMPID5311\n",
              "30  x_1112753546022901                                          WMPID5311\n",
              "31  x_1112776786022012                                          WMPID5311\n",
              "32  x_1112914976087648            WMPID5288|WMPID5288|WMPID5288|WMPID5288\n",
              "33  x_1117725982470547  WMPID4125|WMPID4125|WMPID4125|WMPID1289|WMPID4...\n",
              "34  x_1117741542280486                        WMPID777|WMPID777|WMPID3166\n",
              "35  x_1120206595269097                                          WMPID1217\n",
              "36  x_1120326481935836                                          WMPID3765\n",
              "37  x_1124823858156980                                          WMPID3765\n",
              "38  x_1131575094135014                                          WMPID5311\n",
              "39  x_1133664013902038                                          WMPID3388\n",
              "40  x_1134135070864734                                          WMPID3765\n",
              "41  x_1135024807097239                                          WMPID1413\n",
              "42  x_1135171847374411                                          WMPID3765\n",
              "43  x_1135591164060434  WMPID1006|WMPID1006|WMPID1006|WMPID1006|WMPID1...\n",
              "44  x_1137783003500129                                          WMPID1149\n",
              "45  x_1138058087143760  WMPID4125|WMPID4125|WMPID4125|WMPID1289|WMPID4...\n",
              "46  x_1138316726788686                                           WMPID158\n",
              "47  x_1140417129914133                                          WMPID5311\n",
              "48  x_1143016069929215                                          WMPID5311\n",
              "49  x_1144505956492360                                          WMPID1370"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a7894741-2e3a-4102-b634-2aeaffe65d33\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ad_id</th>\n",
              "      <th>detected_entities</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>x_1004064094349321</td>\n",
              "      <td>WMPID5324</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>x_1014790769921103</td>\n",
              "      <td>WMPID5311</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>x_1015736559308167</td>\n",
              "      <td>WMPID1289</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>x_1030753497615500</td>\n",
              "      <td>WMPID5288|WMPID5288|WMPID5288|WMPID5288</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>x_1035272853805340</td>\n",
              "      <td>WMPID5206|WMPID5206</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>x_1042674793114285</td>\n",
              "      <td>WMPID4125|WMPID4125|WMPID4125|WMPID1289|WMPID4...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>x_1047779595902145</td>\n",
              "      <td>WMPID5311</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>x_1066648220639547</td>\n",
              "      <td>WMPID1289</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>x_1069861830399015</td>\n",
              "      <td>WMPID1069|WMPID1069|WMPID1069</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>x_1070531630300440</td>\n",
              "      <td>WMPID3765</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>x_1075816219803458</td>\n",
              "      <td>WMPID5311</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>x_1076667379659593</td>\n",
              "      <td>WMPID5311</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>x_1080800939304636</td>\n",
              "      <td>WMPID21|WMPID21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>x_1082386059310872</td>\n",
              "      <td>WMPID4511</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>x_1083276702372073</td>\n",
              "      <td>WMPID5311</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>x_1083642688983769</td>\n",
              "      <td>WMPID5339</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>x_1086972378677092</td>\n",
              "      <td>WMPID5311</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>x_1087942005205168</td>\n",
              "      <td>WMPID4125|WMPID4125|WMPID4125|WMPID1289|WMPID4...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>x_1088126968505263</td>\n",
              "      <td>WMPID3765</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>x_1088346575218148</td>\n",
              "      <td>WMPID5334</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>x_1089616945280729</td>\n",
              "      <td>WMPID4308|WMPID4308|WMPID4308|WMPID4308|WMPID4...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>x_1090717081582950</td>\n",
              "      <td>WMPID5311</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>x_1091640268379977</td>\n",
              "      <td>WMPID4125|WMPID4125|WMPID4125|WMPID1289|WMPID4...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>x_1094882458083956</td>\n",
              "      <td>WMPID3388</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>x_1103395850571337</td>\n",
              "      <td>WMPID4511</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>x_1104384606931179</td>\n",
              "      <td>WMPID5334</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>x_1105871176716617</td>\n",
              "      <td>WMPID3765</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>x_1106120006979848</td>\n",
              "      <td>WMPID5311</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>x_1107268893319851</td>\n",
              "      <td>WMPID5341</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>x_1109228639727522</td>\n",
              "      <td>WMPID5311</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>x_1112753546022901</td>\n",
              "      <td>WMPID5311</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>x_1112776786022012</td>\n",
              "      <td>WMPID5311</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>x_1112914976087648</td>\n",
              "      <td>WMPID5288|WMPID5288|WMPID5288|WMPID5288</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>x_1117725982470547</td>\n",
              "      <td>WMPID4125|WMPID4125|WMPID4125|WMPID1289|WMPID4...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>x_1117741542280486</td>\n",
              "      <td>WMPID777|WMPID777|WMPID3166</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>x_1120206595269097</td>\n",
              "      <td>WMPID1217</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>x_1120326481935836</td>\n",
              "      <td>WMPID3765</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>x_1124823858156980</td>\n",
              "      <td>WMPID3765</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>x_1131575094135014</td>\n",
              "      <td>WMPID5311</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>x_1133664013902038</td>\n",
              "      <td>WMPID3388</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>x_1134135070864734</td>\n",
              "      <td>WMPID3765</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>x_1135024807097239</td>\n",
              "      <td>WMPID1413</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>x_1135171847374411</td>\n",
              "      <td>WMPID3765</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>x_1135591164060434</td>\n",
              "      <td>WMPID1006|WMPID1006|WMPID1006|WMPID1006|WMPID1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>x_1137783003500129</td>\n",
              "      <td>WMPID1149</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>x_1138058087143760</td>\n",
              "      <td>WMPID4125|WMPID4125|WMPID4125|WMPID1289|WMPID4...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>x_1138316726788686</td>\n",
              "      <td>WMPID158</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>x_1140417129914133</td>\n",
              "      <td>WMPID5311</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>x_1143016069929215</td>\n",
              "      <td>WMPID5311</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>x_1144505956492360</td>\n",
              "      <td>WMPID1370</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a7894741-2e3a-4102-b634-2aeaffe65d33')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a7894741-2e3a-4102-b634-2aeaffe65d33 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a7894741-2e3a-4102-b634-2aeaffe65d33');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-67566a27-1b28-4ed8-b4f2-e5d5f069ddd8\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-67566a27-1b28-4ed8-b4f2-e5d5f069ddd8')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-67566a27-1b28-4ed8-b4f2-e5d5f069ddd8 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data",
              "summary": "{\n  \"name\": \"data\",\n  \"rows\": 574,\n  \"fields\": [\n    {\n      \"column\": \"ad_id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 574,\n        \"samples\": [\n          \"x_810434977043294\",\n          \"x_1213374399240436\",\n          \"x_1535619720242253\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"detected_entities\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 87,\n        \"samples\": [\n          \"WMPID2166\",\n          \"WMPID5324\",\n          \"WMPID2961\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "# Examine results\n",
        "\n",
        "data = pd.read_csv('/content/detected_entities_fb22.csv.gz')\n",
        "data.head(50)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NACw73q16xSQ"
      },
      "source": [
        "# Results Analysis Example"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H8CqQ-C47F9c"
      },
      "source": [
        "Steps to take before attempting to run:\n",
        "\n",
        "- **Make sure that ```readcsv.py``` and any data that you want to analyze are uploaded onto Google Drive. If they are not directly located in your main drive (e.g, they are in a folder) then the paths used in the code cells must be updated.**\n",
        "\n",
        "  - File [```readcsv.py```](https://github.com/Wesleyan-Media-Project/entity_linking_2022_usabilitystudy/blob/main/analysis/readcsv.py) can be downloaded/uploaded manually using the link provided.\n",
        "  - [Data](https://github.com/Wesleyan-Media-Project/entity_linking_2022_usabilitystudy/tree/main/facebook/data) will either already be present as output from running various sections of this notebook, or you can download/upload files directly from the GitHub repository from the link provided. If you upload data manually, then the path must be changed accordingly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jOBzsGSmjGFJ",
        "outputId": "ea342c5b-95dc-4b40-e750-e50e18097465",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "usage: readcsv.py [-h] --file FILE [--skiprows SKIPROWS] [--nrows NROWS]\n",
            "                  [--filter_text FILTER_TEXT]\n",
            "\n",
            "Filter large CSV files and save results to multiple Excel files if necessary.\n",
            "\n",
            "options:\n",
            "  -h, --help            show this help message and exit\n",
            "  --file FILE           Path to the CSV file.\n",
            "  --skiprows SKIPROWS   Number of rows to skip at the start of the file.\n",
            "  --nrows NROWS         Number of rows to read from the file. Read 10000 rows if not specified.\n",
            "  --filter_text FILTER_TEXT\n",
            "                        Text to filter the rows.\n"
          ]
        }
      ],
      "source": [
        "!python /content/drive/MyDrive/readcsv.py --h"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "htDAvUCd61jq",
        "outputId": "0b640220-ee33-4b53-e45f-3cd7d40d0721"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input file: /content/entity_linking_results_fb22.csv.gz\n",
            "Start reading data from row: 0\n",
            "Number of rows to read: 10000\n",
            "Filter text: No filter is applied\n",
            "Filtered data saved to: Readcsv_Output_20241130_164043.xlsx\n"
          ]
        }
      ],
      "source": [
        "!python /content/drive/MyDrive/readcsv.py --file /content/entity_linking_results_fb22.csv.gz"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "uw1nuufm0ZrV"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}